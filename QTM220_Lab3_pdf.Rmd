---
title: \bf\textsc{\large QTM220 LAB 3\\ 1. Violation of SLM4 and biasedness discussed through simulation\\ 2. Empirical Example} 
date: \textsc{\today}
documentclass: article
fontsize: 10pt 
geometry: margin=0.7in 
output: pdf_document
header-includes:
  - \usepackage{utopia}
  - \usepackage{enumerate}
  - \usepackage[onehalfspacing]{setspace}
  - \usepackage{hyperref}
  - \usepackage{enumitem}
  - \newcommand{\benum}{\begin{enumerate}}
  - \newcommand{\eenum}{\end{enumerate}}
  - \newcommand{\bitem}{\begin{itemize}}
  - \newcommand{\eitem}{\end{itemize}}
---

```{r setup, include=TRUE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE, prompt=FALSE, message = FALSE,comment=NA )
rm(list=ls(all=TRUE))
```

```{r, echo=FALSE}
if(!require(wooldridge)){
    install.packages("wooldridge")
    library(wooldridge)
}
if(!require(ggplot2)){
    install.packages("ggplot2")
    library(ggplot2)
}
if(!require(mvtnorm)){
    install.packages("mvtnorm")
    library(mvtnorm)
}
```

\large In this note, first we will simulate the model such that SLR 4 is not satisfied in the simple linear regression model and discuss about the bias of the slope estimator. Next, we will revisit the wage equation that we fit during LAB 1.

\section{Population I}

In this note, we will simulate the population where SLR 4 is not satisfied. Specifically consider the population model below:
\begin{align*}
y=\beta_{0}+\beta_{1}x_{1}+\beta_{2}x_{2}+u
\end{align*}
where $\beta_{0}=\beta_{1}=0$ and $\beta_{2}=2$ with $u\sim N(0,4)$. However, your estimating model is the simple linear regression model below because $x_{2}$ is not available:
\begin{align*}
y=\beta_{0}+\beta_{1}x_{1}+u'
\end{align*}
For the SLM 4 to be violated $x_{1}$ and $x_{2}$ should be correlated because in the population model, $u$ and $x_{1}$ are independent by construction. (Note that $u$ are drawn from a normal distribution which does not depend on $x_{1}$.) To make the simulation setting such that SLM 4 is violated in the estimating equation, we will be drawing $x_{1}$ and $x_{2}$ from the bivariate normal distribution with mean $\left(\begin{array}{c}0\\0\end{array}\right)$ and variance-covariance matrix $\left(\begin{array}{cc}1&0.5\\0.5&1\end{array}\right)$:
\begin{align*}
\left(\begin{array}{c}x_{1}\\x_{2}\end{array}\right)\sim N\left(\left(\begin{array}{c}0\\0\end{array}\right),\left(\begin{array}{cc}1&0.5\\0.5&1\end{array}\right)\right)
\end{align*}
Generate $N=70$ sample from population and estimate $\hat\beta_{1}$ from the simple linear regression model. Repeat this 1000 times and obtain the mean of $1,000$ $\hat\beta_{1}$s.
\color{blue} 

\benum

\item What do you think would be the average of the $\hat\beta_{1}$? Would it be smaller than $0$? Larger than $0$? Around $0$?

\item What if we regress $y$ on $x_{1}$ and $x_{2}$?

\eenum

\color{black}

```{r}
niter=1000
beta1_list1=rep(NA,niter)
beta1_list2=rep(NA,niter)

beta0=0
beta1=0
beta2=2
nobs=70
mean=c(0,0)
cov= matrix(c(1, 0.5, 0.5, 1), nrow=2, ncol=2)


set.seed(123)
for (i in 1:niter){
  generated_seq=rmvnorm(nobs, mean = mean, sigma = cov)
  generated_u=rnorm(nobs,0,2)
  y=beta0+beta1*generated_seq[,1]+beta2*generated_seq[,2]+generated_u
  df=data.frame(y=y,x1=generated_seq[,1],x2=generated_seq[,2])
  fit1=lm(y~x1,data=df)
  beta1_list1[i]=fit1$coefficients[2]
  fit2=lm(y~x1+x2,data=df)
  beta1_list2[i]=fit2$coefficients[2]
}
sprintf('Mean with x1 only %.2f',mean(beta1_list1))
sprintf('Mean with x1 and x2 %.2f',mean(beta1_list2))
```

Next, plot the histogram of obtained $\hat\beta_{1}$:

```{r, out.width = '80%', fig.align="center"}
df_result1=data.frame(beta1_hat=beta1_list1,label='x1 only')
df_result2=data.frame(beta1_hat=beta1_list2,label='x1 and x2')
df_result=rbind(df_result1,df_result2)

gout1<-ggplot(aes(x=beta1_hat),data=df_result1)+
  geom_histogram(alpha=0.5, fill='plum4')+
  ggtitle("x1 only")+
  xlab(expression(hat(beta)[1]))+
  theme(plot.title = element_text(hjust = 0.5,size=13),
        plot.background = element_rect(colour = "gray"),
        panel.background = element_rect(fill = "white", colour = NA),
        panel.grid.major = element_blank(), 
        axis.title=element_text(size=14),
        legend.text=element_text(size=14),
        legend.title=element_text(size=14)
  )+
  geom_vline(xintercept=beta1, color='khaki',linetype = "longdash")
                  
gout2<-ggplot(aes(x=beta1_hat),data=df_result2)+
  geom_histogram(alpha=0.5)+
  ggtitle("x1 and x2")+
  xlab(expression(hat(beta)[1]))+
  theme(plot.title = element_text(hjust = 0.5,size=13),
        plot.background = element_rect(colour = "gray"),
        panel.background = element_rect(fill = "white", colour = NA),
        panel.grid.major = element_blank(), 
        axis.title=element_text(size=14),
        legend.text=element_text(size=14),
        legend.title=element_text(size=14)
  )+
  geom_vline(xintercept=beta1, color='khaki',linetype = "longdash")

gout3<-ggplot(aes(x=beta1_hat,group=label,fill=label),data=df_result)+
  geom_histogram(alpha=0.8)+
  scale_fill_manual(values = c("gray", "plum4"))+
  xlab(expression(hat(beta)[1]))+
   theme(plot.title = element_text(hjust = 0.5,size=13),
        plot.background = element_rect(colour = "gray"),
        panel.background = element_rect(fill = "white", colour = NA),
        panel.grid.major = element_blank(), 
        axis.title=element_text(size=14),
        legend.text=element_text(size=14),
        legend.title=element_text(size=14),
        legend.position = "bottom"
  )+
  geom_vline(xintercept=beta1, color='khaki',linetype = "longdash")

gout1
gout2
gout3
```


\section{Population II}
Next, consider the same population as above, Population I, but $\beta_{2}=-2$ (previously it was $\beta_{2}=2$). Hence the population is 
\begin{align*}
y=\beta_{0}+\beta_{1}x_{1}+\beta_{2}x_{2}+u
\end{align*}
where $\beta_{0}=\beta_{1}=0$ and $\beta_{2}=-2$ with $u\sim N(0,4)$ and
\begin{align*}
\left(\begin{array}{c}x_{1}\\x_{2}\end{array}\right)\sim N\left(\left(\begin{array}{c}0\\0\end{array}\right),\left(\begin{array}{cc}1&0.5\\0.5&1\end{array}\right)\right)
\end{align*}
However, your estimating model is the simple linear regression model below because $x_{2}$ is not available:
\begin{align*}
y=\beta_{0}+\beta_{1}x_{1}+u'
\end{align*}
Generate $N=70$ sample from population and estimate $\hat\beta_{1}$ from the simple linear regression model. Repeat this 1000 times and obtain the mean of $1,000$ $\hat\beta_{1}$s.
\color{blue} What do you think would be the average of the $\hat\beta_{1}$? Would it be smaller than 0? Larger than 0? Around 0?

\color{black}

```{r}
niter=1000
beta1_list1=rep(NA,niter)
beta1_list2=rep(NA,niter)

beta0=0
beta1=0
beta2=-2
nobs=70
mean=c(0,0)
cov= matrix(c(1, 0.5, 0.5, 1), nrow=2, ncol=2)


set.seed(123)
for (i in 1:niter){
  generated_seq=rmvnorm(nobs, mean = mean, sigma = cov)
  generated_u=rnorm(nobs,0,2)
  y=beta0+beta1*generated_seq[,1]+beta2*generated_seq[,2]+generated_u
  df=data.frame(y=y,x1=generated_seq[,1],x2=generated_seq[,2])
  fit1=lm(y~x1,data=df)
  beta1_list1[i]=fit1$coefficients[2]
  
  fit2=lm(y~x1+x2,data=df)
  beta1_list2[i]=fit2$coefficients[2]
}
sprintf('Mean with x1 only %.2f',mean(beta1_list1))
sprintf('Mean with x1 and x2 %.2f',mean(beta1_list2))
```

Next, plot the histogram of obtained $\hat\beta_{1}$:
```{r, out.width = '80%', fig.align="center"}
df_result1=data.frame(beta1_hat=beta1_list1,label='x1 only')
df_result2=data.frame(beta1_hat=beta1_list2,label='x1 and x2')
df_result=rbind(df_result1,df_result2)

gout1<-ggplot(aes(x=beta1_hat),data=df_result1)+
  geom_histogram(alpha=0.5, fill='plum4')+
  ggtitle("x1 only")+
  xlab(expression(hat(beta)[1]))+
  theme(plot.title = element_text(hjust = 0.5,size=13),
        plot.background = element_rect(colour = "gray"),
        panel.background = element_rect(fill = "white", colour = NA),
        panel.grid.major = element_blank(), 
        axis.title=element_text(size=14),
        legend.text=element_text(size=14),
        legend.title=element_text(size=14)
  )+
  geom_vline(xintercept=beta1, color='khaki',linetype = "longdash")
                  
gout2<-ggplot(aes(x=beta1_hat),data=df_result2)+
  geom_histogram(alpha=0.5)+
  ggtitle("x1 and x2")+
  xlab(expression(hat(beta)[1]))+
  theme(plot.title = element_text(hjust = 0.5,size=13),
        plot.background = element_rect(colour = "gray"),
        panel.background = element_rect(fill = "white", colour = NA),
        panel.grid.major = element_blank(), 
        axis.title=element_text(size=14),
        legend.text=element_text(size=14),
        legend.title=element_text(size=14)
  )+
  geom_vline(xintercept=beta1, color='khaki',linetype = "longdash")

gout3<-ggplot(aes(x=beta1_hat,group=label,fill=label),data=df_result)+
  geom_histogram(alpha=0.8)+
  scale_fill_manual(values = c("gray", "plum4"))+
  xlab(expression(hat(beta)[1]))+
   theme(plot.title = element_text(hjust = 0.5,size=13),
        plot.background = element_rect(colour = "gray"),
        panel.background = element_rect(fill = "white", colour = NA),
        panel.grid.major = element_blank(), 
        axis.title=element_text(size=14),
        legend.text=element_text(size=14),
        legend.title=element_text(size=14),
        legend.position = "bottom"
  )+
  geom_vline(xintercept=beta1, color='khaki',linetype = "longdash")

gout1
gout2
gout3
```

\section{Population III}
Next, consider the same population as above, Population I, but covariance between x_{1} and x_{2} is $-0.5$ (previously it was $0.5$). Hence the population is 
\begin{align*}
y=\beta_{0}+\beta_{1}x_{1}+\beta_{2}x_{2}+u
\end{align*}
where $\beta_{0}=\beta_{1}=0$ and $\beta_{2}=2$ with $u\sim N(0,4)$ and
\begin{align*}
\left(\begin{array}{c}x_{1}\\x_{2}\end{array}\right)\sim N\left(\left(\begin{array}{c}0\\0\end{array}\right),\left(\begin{array}{cc}1&-0.5\\-0.5&1\end{array}\right)\right)
\end{align*}
However, your estimating model is the simple linear regression model below because $x_{2}$ is not available:
\begin{align*}
y=\beta_{0}+\beta_{1}x_{1}+u'
\end{align*}

\color{blue} What do you think would be the average of the $\hat\beta_{1}$? Would it be smaller than 0? Larger than 0? Around 0?

\color{black}

```{r}
niter=1000
beta1_list1=rep(NA,niter)
beta1_list2=rep(NA,niter)

beta0=0
beta1=0
beta2=2
nobs=70
mean=c(0,0)
cov= matrix(c(1, -0.5, -0.5, 1), nrow=2, ncol=2)
generated_u=rnorm(nobs,0,2)

set.seed(123)

for (i in 1:niter){
  generated_seq=rmvnorm(nobs, mean = mean, sigma = cov)
  generated_u=rnorm(nobs,0,2)3
  y=beta0+beta1*generated_seq[,1]+beta2*generated_seq[,2]+generated_u
  df=data.frame(y=y,x1=generated_seq[,1],x2=generated_seq[,2])
  fit1=lm(y~x1,data=df)
  beta1_list1[i]=fit1$coefficients[2]
  
  fit2=lm(y~x1+x2,data=df)
  beta1_list2[i]=fit2$coefficients[2]
}
sprintf('Mean with x1 only %.2f',mean(beta1_list1))
sprintf('Mean with x1 and x2 %.2f',mean(beta1_list2))
```

Next, plot the histogram of obtained $\hat\beta_{1}$:
```{r, out.width = '80%', fig.align="center"}
df_result1=data.frame(beta1_hat=beta1_list1,label='x1 only')
df_result2=data.frame(beta1_hat=beta1_list2,label='x1 and x2')
df_result=rbind(df_result1,df_result2)

gout1<-ggplot(aes(x=beta1_hat),data=df_result1)+
  geom_histogram(alpha=0.5, fill='plum4')+
  ggtitle("x1 only")+
  xlab(expression(hat(beta)[1]))+
  theme(plot.title = element_text(hjust = 0.5,size=13),
        plot.background = element_rect(colour = "gray"),
        panel.background = element_rect(fill = "white", colour = NA),
        panel.grid.major = element_blank(), 
        axis.title=element_text(size=14),
        legend.text=element_text(size=14),
        legend.title=element_text(size=14)
  )+
  geom_vline(xintercept=beta1, color='khaki',linetype = "longdash")
                  
gout2<-ggplot(aes(x=beta1_hat),data=df_result2)+
  geom_histogram(alpha=0.5)+
  ggtitle("x1 and x2")+
  xlab(expression(hat(beta)[1]))+
  theme(plot.title = element_text(hjust = 0.5,size=13),
        plot.background = element_rect(colour = "gray"),
        panel.background = element_rect(fill = "white", colour = NA),
        panel.grid.major = element_blank(), 
        axis.title=element_text(size=14),
        legend.text=element_text(size=14),
        legend.title=element_text(size=14)
  )+
  geom_vline(xintercept=beta1, color='khaki',linetype = "longdash")

gout3<-ggplot(aes(x=beta1_hat,group=label,fill=label),data=df_result)+
  geom_histogram(alpha=0.8)+
  scale_fill_manual(values = c("gray", "plum4"))+
  xlab(expression(hat(beta)[1]))+
   theme(plot.title = element_text(hjust = 0.5,size=13),
        plot.background = element_rect(colour = "gray"),
        panel.background = element_rect(fill = "white", colour = NA),
        panel.grid.major = element_blank(), 
        axis.title=element_text(size=14),
        legend.text=element_text(size=14),
        legend.title=element_text(size=14),
        legend.position = "bottom"
  )+
  geom_vline(xintercept=beta1, color='khaki',linetype = "longdash")

gout1
gout2
gout3

```


\section{Empirical Example with Simple Linear Regression Model}

\large Suppose that we are interested in the following model
\begin{align*}
wage=\beta_{0}+\beta_{1}educ+u
\end{align*}
where $wage$ is average hourly earnings and $educ$ is years of education (1976 data).

\color{blue}
\benum

\item What is $SE(\hat\beta_{1})$?
\item What is $\hat\sigma$?
\item What is the number of observations?

\eenum

\color{black}
\normalsize 

```{r}
data("wage1")
df_wage=wage1[,c('wage','educ')]
fit=lm(wage~educ,data=df_wage)



sprintf('SE of hatbeta1 is %.3f',summary(fit)$coefficients[2,2])

sprintf('SE of error is %.3f', summary(fit)$sigma)

sprintf('The number of observations is %.0f', fit$df.residual+2)


vcov(fit)

```

\bitem

\item The standard error of $\hat\beta_{1}$ which is the square root of the estimated variance is 
`r round(summary(fit)$coefficients[2,2],2)`.
\begin{align*}
\sqrt{\frac{\hat\sigma^{2}}{\sum_{(x_{i}-\overline{x})^{2}}}}=\frac{\hat\sigma}{\sqrt{\sum(x_{i}-\overline{x})^{2}}}=0.05325
\end{align*}

\item The $\hat\sigma$ is `r round(summary(fit)$sigma,2)`.

\item The number of observations is `r fit$df.residual+2`

\eitem
