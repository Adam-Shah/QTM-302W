---
title: 'QTM 220 Homework #4'
author: "Adam Shah"
date: "10/28/2021"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(mvtnorm)
library(multcomp)
library(car)
library(wooldridge)
```

## 1.
i) Heteroskedasticity would invalidate the t-statistic because the t-statistic relies on the assumption that the variance of estimators given x can be expressed as a constant, sigma squared. 
ii) A high correlation coefficient between two explanatory variables does not matter as long as it is not 1. 
iii) Omitting an important explanatory variable would matter as it would violate MLR 3. 

## 2. 
i) H0: beta3-beta2=0 
  H1: beta3-beta2 does not equal 0
ii)
```{r}
# Way 1
data("wage2")
fit=lm(lwage~educ+exper+tenure, data=wage2)
summary(fit)
fit$coefficients[3]
fit$coefficients[4]

B3_B2= fit$coefficients[4]-fit$coefficients[3]
B3_B2 

vcov(fit)
se_B3_B2=sqrt(vcov(fit)[3,3]+vcov(fit)[4,4]-2*vcov(fit)[3,4]) 

t2=B3_B2/se_B3_B2
t2

sig=0.05
critical_val=qt(1-sig/2,df=fit$df.residual) 
lower=B3_B2-critical_val*se_B3_B2
upper=B3_B2+critical_val*se_B3_B2
sprintf("95 percent confidence= [%.3f %.3f]", lower, upper)

# Way 2
wage2$theta=wage2$exper+wage2$tenure  
new_fit<-lm(lwage~educ+theta+tenure,data=wage2) 
summary(new_fit) 
confint(new_fit,'tenure',level=0.95, df=fit$df.residual)
```

## 3. 
```{r}
data("k401ksubs")
Q3 <- k401ksubs[k401ksubs$fsize==1,] 
fit=lm(nettfa~inc+age, data=Q3) 
summary(fit) 

coef(fit)
coef(summary(fit))[, 2][3] 

sig=0.01
crit=qt(sig,df=fit$df.residual)
crit

t3 <- (fit$coefficients[3] - 1) / coef(summary(fit))[, 2][3]
t3
pnorm(t3)
```
We fail to reject H0 at 1% significance- the p-value was 0.0436, which is greater than 0.01.

## 4. 
```{r}
#ii
data("discrim")
discrim2 <- discrim[,c('prpblck', 'prppov')]
discrim2$lpsoda <- log(discrim$psoda)
discrim2$lincome <- log(discrim$income)
cor.test(discrim2$prppov, discrim2$lincome) 

fit=lm(lpsoda~prpblck+lincome+prppov, data=discrim2)
summary(fit) 

coef(summary(fit))[, 3][4]
2*(1-pnorm(coef(summary(fit))[, 3][4]))

coef(summary(fit))[, 3][3]
2*(1-pnorm(coef(summary(fit))[, 3][3]))

#iii
discrim2$lhseval <- log(discrim$hseval)
fit2=lm(lpsoda~prpblck+lincome+prppov+lhseval, data=discrim2)
summary(fit2)
coef(summary(fit2))[, 3][5]
2*(1-pnorm(coef(summary(fit2))[, 3][5]))

#iv
coef(summary(fit2))[, 3][4]
2*(1-pnorm(coef(summary(fit2))[, 3][4]))

coef(summary(fit))[, 3][3]
2*(pnorm(coef(summary(fit))[, 3][3]))

restricted=lm(lpsoda~prpblck+lhseval, data=discrim2) 
unrestricted=lm(lpsoda~prpblck+lincome+prppov+lhseval, data=discrim2) 
ssr_rest=sum(restricted$residuals^2)
ssr_unrest=sum(unrestricted$residuals^2)
F4=((ssr_rest-ssr_unrest)/2)/(ssr_unrest/unrestricted$df.residual) 
F4

qf(0.95 , df1=2, df2=unrestricted$df.residual)
1-pf(F4, df1=2, df2=unrestricted$df.residual)

```
ii) prppov and lincome have a correlation of -0.838, and both have statistically significant p-values- prppov has a two-sided p-value of 0.00418, and lincome has a p-value of 3.07e-7. The correlation between prpblck and lincome is -0.838467. 

iii) The beta coefficient of lhseval demonstrates that soda increases by 0.12 percent for each percent increase in hseval. This variable has a statistically significant p-value of 6.91e-12.

iv) The p-values of both variables increased, meaning that their individual statistical significance decreased. They are jointly significant- F was 3.52 with the critical value for 95% significance at 3.02, and the p-value was 0.0304. However, the joint significance has decreased, most likely due to the high correlation between lhseval and lincome as well as prppov. Much of the variation in lpsoda due to lhseval was still accounted for by the other two variables when absent, but lhseval's inclusion lowers the significance of prppov and lincome. 

