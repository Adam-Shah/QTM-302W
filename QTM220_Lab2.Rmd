---
title: \bf\textsc{\large QTM220 LAB1 Fitting simple linear regression model}
date: \textsc{\today}
documentclass: article
fontsize: 10pt 
geometry: margin=0.7in 
output: pdf_document
header-includes:
  - \usepackage{utopia}
  - \usepackage{enumerate}
  - \usepackage[onehalfspacing]{setspace}
  - \usepackage{hyperref}
  - \usepackage{enumitem}
  - \newcommand{\benum}{\begin{enumerate}}
  - \newcommand{\eenum}{\end{enumerate}}
  - \newcommand{\bitem}{\begin{itemize}}
  - \newcommand{\eitem}{\end{itemize}}
---

```{r setup, include=TRUE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE, prompt=FALSE, message = FALSE,comment=NA )
```

```{r, include=TRUE, echo=FALSE}
rm(list=ls(all=TRUE))

if(!require(wooldridge)){
    install.packages("wooldridge")
    library(wooldridge)
}

if(!require(ggplot2)){
    install.packages("ggplot2")
    library(ggplot2)
}
```

\large In this note, we will simulate the distribution of the OLS estimator $\hat\beta_{1}$. The simulation result would show that $\hat\beta_{1}$ is indeed an unbiased estimator. We would also discuss how thee variance of $\hat\beta_{1}$ changes as the variance of $x$ and the variance of $u$ change.

\normalsize
\section{Population I}
We will first define the population (true world) and generate data from it. Suppose that the population regression function is $E[y\vert x]=2x$. The relevant equation would be 
\begin{align*}
y=\beta_{0}+\beta_{1}x+u
\end{align*}
with $\beta_{0}=0$ and $\beta_{1}=2$. This is not enough to generate the data. We have to define the distribution of $x$ and $u$ to compute $y$. Suppose that $x\sim N(0,4)$ and $u\sim N(0,1)$ and let $N=70$.


\color{blue}$\bullet$ 1. Generate 70 observations and compute the OLS estimate $\hat\beta_{1}$
\color{black}
```{r}
nobs=70
beta0=0
beta1=2
x=rnorm(nobs, mean=0, sd = 2)
u=rnorm(nobs,mean=0,sd=1)
y=beta0+beta1*x+u
df=data.frame(y=y,x=x)
fit=lm(y~x,data=df)
summary(fit)
```

\color{blue}$\bullet$ 2. Create loop so that above step 1 is repeated $10,000$ times and save $10,000$ $\hat\beta_{1}$ estimates in a vector.
\color{black}
```{r}
nobs=70
beta0=0
beta1=2
niter=10000
list_beta1_pop1=rep(NA,niter )

set.seed(123)
for (iter in 1:niter){
  x=rnorm(nobs, mean=0, sd = 2)
  u=rnorm(nobs,mean=0,sd=1)
  y=beta0+beta1*x+u
  df=data.frame(y=y,x=x)
  fit=lm(y~x,data=df)
  list_beta1_pop1[iter]=fit$coefficients[2]
}
```


\color{blue}$\bullet$ 3. What is the mean and the variance of $\hat\beta_{1}$ distribution? Plot the edistributuion with mean. 
\color{black}

```{r}
sprintf("The mean of slope parameter estimates is %.2f",mean(list_beta1_pop1))
sprintf("The sample standard deviation of slope parameter estimates is %.2f",sd(list_beta1_pop1))
```

The mean of $\hat\beta_{1}$ across 10,000 iterations is `r round(mean(list_beta1_pop1),2)` and the sample standard deviation is `r round(sd(list_beta1_pop1),2)`.

The plot of the distribution of $\hat\beta_{1}$ with 10,000 estimates is reported below:
```{r}
df_result=data.frame(beta1=list_beta1_pop1)
gout<- ggplot(df_result, aes(x=beta1)) +
   geom_histogram(colour="lightgray")+
    geom_vline(aes(xintercept = mean(beta1)),
             colour = "green", linetype ="longdash", size = .8)+
    theme(plot.title = element_text(hjust = 0.5,size=13),
      panel.background = element_rect(fill = "white", colour = NA),
      panel.grid.major = element_blank(),
      panel.grid.minor = element_blank(),
      axis.title=element_text(size=13),
      axis.line = element_line(colour = "grey92", size = 1, linetype = "solid")
  )+
   xlab(expression(widehat(beta)[1]))
gout
```

\section{Population II}
Let population regression function be identical as before and also let $x\sim N(0,4)$. However for the second population we would assume that $u\sim N(0,9)$. 

\benum

\item Do you expect the mean of $\hat\beta_{1}$ to be near 2 (unbiased estimator)? 
\item What about the standard deviation of $\hat\beta_{1}$? Do you expect this to be larger or smaller that the standard deviation of $\hat\beta_{1}$ in the previous population, population I?

\eenum

Let $N=70$ and the number of iterations to be $10,000$. Run the simulation as we've done for population I. 

```{r}
nobs=70
niter=10000
beta0=0
beta1=2

list_beta1_pop2=rep(NA,niter)

set.seed(123)
for(iter in 1:niter){
  x=rnorm(nobs, mean=0, sd=2)
  u=rnorm(nobs, mean=0, sd=3)
  y=beta0+beta1*x+u
  df=data.frame(x=x,y=y)
  fit=lm(y~x, data=df)
  list_beta1_pop2[iter]=fit$coefficients[2]
}

mean(list_beta1_pop2)
sd(list_beta1_pop2)

sd(list_beta1_pop1)
#sd increased
```


\section{Population III}
Let population regression function be identical as before and also let $u\sim N(0,1)$. However for the second population we would assume that $x\sim N(0,16)$. 

\benum

\item Do you expect the mean of $\hat\beta_{1}$ to be near 2 (unbiased estimator)? 
\item What about the standard deviation of $\hat\beta_{1}$? Do you expect this to be larger or smaller that the standard deviation of $\hat\beta_{1}$ in the previous population, population I?

\eenum

Let $N=70$ and the number of iterations to be $10,000$. Run the simulation as we've done for population I. 

```{r}
nobs=70
niter=10000
beta0=0
beta1=2

list_beta1_pop3=rep(NA,niter)

set.seed(123)
for (iter in 1:niter){
  x=rnorm(nobs, mean=0, sd=4)
  u=rnorm(nobs, mean=0, sd=1)
  y=beta0+beta1*x+u
  df=data.frame(x=x,y=y)
  fit=lm(y~x, data=df)
  list_beta1_pop3[iter]=fit$coefficients[2]
}

mean(list_beta1_pop3)
sd(list_beta1_pop3)
sd(list_beta1_pop1)

#model 3 has same mean but lower sd as model 1

```







Computing $R^{2}$

```{r}
fit_r2=lm(y~x, data=df_result)

SST=sum((y-mean(y))^2)
SSE=sum((fit_r2$fitted.values-mean(y))^2)
SSR=sum(fit_r2$residuals^2)

SSE + SSR
SST

R_sq1=SSE/SST
R_sq2=1-SSR/SST

summary(fit_r2)$r.squared

R_sq1==R_sq2
R_sq1==summary(fit_r2)$r.squared

ggplot(aes)
```